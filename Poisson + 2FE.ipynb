{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import scipy.sparse as spr\n",
        "from scipy.optimize import minimize\n",
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "KS7tR3FthYg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File\n",
        "thepath = 'https://raw.githubusercontent.com/math-econ-code/mec_optim_2021-01/master/data_mec_optim/gravity_wtodata/'\n",
        "tradedata = pd.read_csv(thepath + '1_TraditionalGravity_from_WTO_book.csv')\n",
        "\n",
        "# Formatting\n",
        "tradedata = tradedata[['exporter', 'importer','year', 'trade', 'DIST','ln_DIST', 'CNTG', 'LANG', 'CLNY']]\n",
        "tradedata.sort_values(by = ['year','importer','exporter'], inplace = True)\n",
        "tradedata.reset_index(inplace = True, drop = True)\n",
        "\n",
        "# Initiating matrices\n",
        "nbt = len(tradedata['year'].unique())\n",
        "nbi = len(tradedata['importer'].unique())\n",
        "nbk = 4\n",
        "years = tradedata['year'].unique()\n",
        "distances = np.array(['ln_DIST', 'CNTG', 'LANG', 'CLNY'])\n",
        "\n",
        "phi_i_j_t_k = np.zeros((nbi, nbi, nbt, nbk)) # design matrix\n",
        "tradevol_i_j_t = np.zeros((nbi, nbi, nbt)) # dependent variable (trade volumes between each pair of countries across year)\n",
        "pihat_i_j_t = np.zeros((nbi, nbi, nbt)) # normalization of the trade volumes\n",
        "\n",
        "# Filling matrices using data points from tradedata\n",
        "for t, year in enumerate(years):\n",
        "    tradevol_i_j_t[:, :, t] = np.array(tradedata.loc[tradedata['year'] == year, 'trade']).reshape((nbi, nbi))  # store trade flows\n",
        "    np.fill_diagonal(tradevol_i_j_t[:, :, t], 0)  # set to zero the trade within a country\n",
        "    for k, distance in enumerate(distances):\n",
        "        phi_i_j_t_k[:, :, t, k] = np.array(tradedata.loc[tradedata['year'] == year, distance]).reshape((nbi, nbi))  # store distances\n",
        "pihat_i_j_t = tradevol_i_j_t / (tradevol_i_j_t.sum() / len(years)) # normalize by the average annual trade volume\n",
        "\n",
        "# Keeping only the first year of data\n",
        "phi_i_j_k = phi_i_j_t_k[:, :, 0, :]\n",
        "pihat_i_j = pihat_i_j_t[:, :, 0]"
      ],
      "metadata": {
        "id": "g_1Fl2SzdW9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-defined procedure\n",
        "\n",
        "(I, J, K) = phi_i_j_k.shape\n",
        "\n",
        "def mloglikelihood(params):\n",
        "\n",
        "    # Splitting parameters\n",
        "    lambda_k = params[ : K]\n",
        "    u_i = params[K : K+I]\n",
        "    v_j = params[K+I : ]\n",
        "\n",
        "    # Defining terms for expression from q2 a\n",
        "    term1 = (pihat_i_j * ((phi_i_j_k * lambda_k[None, None, :]).sum(axis = 2) - u_i[:, None] - v_j[None, :])).sum(axis = (0,1))\n",
        "    term2 = np.exp((phi_i_j_k * lambda_k[None, None, :]).sum(axis = 2) - u_i[:, None] - v_j[None, :]).sum(axis = (0,1))\n",
        "\n",
        "    return term2 - term1\n",
        "\n",
        "def grad_mloglikelihood(params):\n",
        "\n",
        "    # Splitting parameters\n",
        "    lambda_k = params[ : K]\n",
        "    u_i = params[K : K+I]\n",
        "    v_j = params[K+I : ]\n",
        "\n",
        "    # Defining equality constraints to be satisfied, as stated in q2 b\n",
        "    exp_i_j = np.exp((phi_i_j_k * lambda_k[None, None, :]).sum(axis = 2) - u_i[:, None] - v_j[None, :])\n",
        "\n",
        "    grad_u = (pihat_i_j - exp_i_j).sum(axis = 1) # eq. 1 from q2 b\n",
        "    grad_v = (pihat_i_j - exp_i_j).sum(axis = 0) # eq. 2 from q2 b\n",
        "    grad_lambda = ((exp_i_j - pihat_i_j)[:, :, None] * phi_i_j_k).sum(axis = (0, 1)) # eq. 3 from q2 b\n",
        "\n",
        "    return np.concatenate([grad_lambda, grad_u, grad_v])\n",
        "\n",
        "# Initiating vectors for regressors + i-fixed effects + j-fixed effects\n",
        "lambda0_k = np.zeros(K)\n",
        "u0_i = np.zeros(I)\n",
        "v0_j = np.zeros(J)\n",
        "all_params = np.concatenate([lambda0_k, u0_i, v0_j])\n",
        "\n",
        "result = minimize(mloglikelihood, all_params, jac = grad_mloglikelihood, method = 'BFGS') # minimizing as the input is negative of loglikelihood\n",
        "\n",
        "# Scikit-learn's pre-defined procedure\n",
        "clf = linear_model.PoissonRegressor( alpha = 0,  fit_intercept = False ,max_iter = 2000, tol = 1e-10)\n",
        "X = np.block([[phi_i_j_k.reshape((-1,K)), - np.kron(np.eye(I),np.ones((J,1))), - np.kron(np.ones((J,1)), np.eye(I))]])\n",
        "clf.fit(X, pihat_i_j.flatten())\n",
        "\n",
        "# Comparison between the two\n",
        "print(f'Parameters a/c to own code = {result.x[:K]}')\n",
        "print(f'Parameters a/c to sk-learn = {clf.coef_[:K]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ7IDynWGjaz",
        "outputId": "fbba1165-11bc-46b7-8c7f-c688a6debcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters a/c to own code = [-0.23013921  1.38532591  0.48408635 -0.09585853]\n",
            "Parameters a/c to sk-learn = [-0.23001125  1.38547253  0.48440474 -0.0960905 ]\n"
          ]
        }
      ]
    }
  ]
}
